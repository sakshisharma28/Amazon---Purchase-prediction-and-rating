{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.optimize\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import random\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "users = []\n",
    "items = []\n",
    "category = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user = l['reviewerID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "    users.append(l['reviewerID'])\n",
    "    items.append(l['itemID'])\n",
    "    category.append(l['categories'])\n",
    "\n",
    "    \n",
    "users_train, users_val = users[:100000], users[100000:]\n",
    "items_train, items_val  = items[:100000], items[100000:]\n",
    "category_train, category_val = category[:100000], category[100000:]\n",
    "ratings_train, ratings_val = allRatings[:100000], allRatings[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchasers_dict = defaultdict(list)\n",
    "for u,i in zip(users, items):\n",
    "    purchasers_dict[u].append(i)\n",
    "\n",
    "\n",
    "\n",
    "unique_users = list(set(users))\n",
    "unique_items = list(set(items))\n",
    "\n",
    "non_purchasers = []\n",
    "unpurchased_items = []\n",
    "while len(non_purchasers) <= 99999:\n",
    "    u = random.choice(unique_users)\n",
    "    i = random.choice(unique_items)\n",
    "    if i not in purchasers_dict[u]:\n",
    "        non_purchasers.append(u)\n",
    "        unpurchased_items.append(i)\n",
    "        \n",
    "complete_users_val = users_val + non_purchasers\n",
    "complete_items_val = items_val + unpurchased_items\n",
    "actual_purchase_val = [1]*100000 + [0]*100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purhcase Prediction \n",
    "## Model 1 - Overlapping categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_category_dict = defaultdict(list)\n",
    "item_category_dict = defaultdict(list)\n",
    "\n",
    "for u,c in zip(users_train, category_train):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat in user_category_dict[u]: continue\n",
    "            user_category_dict[u].append(subcat)\n",
    "\n",
    "for i,c in zip(items_train,category_train):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat in item_category_dict[i]: continue\n",
    "            item_category_dict[i].append(subcat)\n",
    "            \n",
    "pred_val = []\n",
    "\n",
    "common_categories = [1,2,3,4,5,6,7,8]\n",
    "accuracy = []\n",
    "\n",
    "for k in common_categories:\n",
    "    pred_val = []\n",
    "    accuracy_val = 0\n",
    "    for u,i in zip(complete_users_val, complete_items_val):\n",
    "        common = 0\n",
    "        c = item_category_dict[i]\n",
    "        if len(c) == 0:\n",
    "            pred_val.append(0)\n",
    "            continue\n",
    "        for subcat in c:\n",
    "            if subcat in user_category_dict[u]:\n",
    "                common += 1\n",
    "        if common >= k:\n",
    "            pred_val.append(1)\n",
    "        else:\n",
    "            pred_val.append(0)\n",
    "  \n",
    "    accuracy_val = float(sum([(a == b) for a,b in zip(pred_val, actual_purchase_val)]))/len(actual_purchase_val)  \n",
    "    accuracy.append(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = common_categories[accuracy.index(max(accuracy))]\n",
    "\n",
    "pred_val = []\n",
    "for u,i in zip(complete_users_val, complete_items_val):\n",
    "    common = 0\n",
    "    c = item_category_dict[i]\n",
    "    if len(c) == 0:\n",
    "        pred_val.append(0)\n",
    "        continue\n",
    "    for subcat in c:\n",
    "        if subcat in user_category_dict[u]:\n",
    "            common += 1\n",
    "    if common >= k:\n",
    "        pred_val.append(1)\n",
    "    else:\n",
    "        pred_val.append(0)\n",
    "        \n",
    "accuracy_val = float(sum([(a == b) for a,b in zip(pred_val, actual_purchase_val)]))/len(actual_purchase_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Common categories = \" + str(k) \n",
    "print \"Accuracy = \" + str(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(pred_val, actual_purchase_val)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_category_dict = defaultdict(list)\n",
    "item_category_dict = defaultdict(list)\n",
    "\n",
    "for u,c in zip(users, category):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat in user_category_dict[u]: continue\n",
    "            user_category_dict[u].append(subcat)\n",
    "            \n",
    "for i,c in zip(items, category):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat in item_category_dict[i]: continue\n",
    "            item_category_dict[i].append(subcat)\n",
    "            \n",
    "            \n",
    "predictions = open(\"predictions_Purchase.csv\", 'w')\n",
    "\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    common = 0\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    c = item_category_dict[i]\n",
    "    if len(c) == 0:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "        continue\n",
    "    for subcat in c:\n",
    "        if subcat in user_category_dict[u]:\n",
    "            common += 1\n",
    "    if common >= 3: \n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########  EDA #####################\n",
    "\n",
    "all_item_cat = defaultdict(list)\n",
    "\n",
    "for i,c in zip(items,category):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat in all_item_cat[i]: continue\n",
    "            all_item_cat[i].append(subcat)\n",
    "            \n",
    "category_list = []\n",
    "\n",
    "for i in items:\n",
    "    category_list.append(all_item_cat[i])\n",
    "    \n",
    "catCount = defaultdict(int)\n",
    "\n",
    "for u,c in zip(users, category_list):\n",
    "    for subcat in c:\n",
    "        catCount[subcat] += 1\n",
    "    \n",
    "mostPopularCat = [(catCount[x], x) for x in catCount]\n",
    "mostPopularCat.sort(reverse = True)\n",
    "mostPopularCat = pd.DataFrame(np.array(mostPopularCat), columns = ('Freq','Category'))\n",
    "mostPopularCat['Freq'] = mostPopularCat['Freq'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPopularCat[:10]\n",
    "plt.bar(mostPopularCat['Category'][:10], mostPopularCat['Freq'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Similarity between items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Finding similarity between items purchased by users, the similarity is > than a threshold then 1 else 0 ###############\n",
    "\n",
    "user_category_dict = defaultdict(list)\n",
    "item_category_dict = defaultdict(list)\n",
    "\n",
    "for u,i,c in zip(users_train, items_train, category_train):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat in user_category_dict[u]: continue\n",
    "            user_category_dict[u].append(subcat)\n",
    "            if subcat in item_category_dict[i]: continue\n",
    "            item_category_dict[i].append(subcat)\n",
    "            \n",
    "\n",
    "threshold = list(np.arange(0.18,0.19,0.001))\n",
    "\n",
    "\n",
    "def jaccard_similarity(set1,set2):\n",
    "    common = set1.intersection(set2)\n",
    "    return float(len(common)) / (len(set1) + len(set2) - len(common))\n",
    "\n",
    "\n",
    "for k in threshold:\n",
    "    pred_val = []\n",
    "    for u,i in zip(complete_users_val,complete_items_val):\n",
    "        new_c = set(item_category_dict[i])\n",
    "        user_c = set(user_category_dict[u])\n",
    "        if len(user_c) <> 0:\n",
    "            similarity = jaccard_similarity(new_c,user_c)\n",
    "            if similarity >= k:\n",
    "                pred_val.append(1)\n",
    "            else:\n",
    "                pred_val.append(0)\n",
    "        else:\n",
    "            pred_val.append(1)\n",
    "    accuracy_val = float(sum([(a == b) for a,b in zip(pred_val, actual_purchase_val)]))/len(actual_purchase_val)  \n",
    "    print k,accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_category_dict = defaultdict(list)\n",
    "item_category_dict = defaultdict(list)\n",
    "\n",
    "for u,i,c in zip(users, items, category):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat not in user_category_dict[u]:\n",
    "                user_category_dict[u].append(subcat)\n",
    "            if subcat not in item_category_dict[i]: \n",
    "                item_category_dict[i].append(subcat)\n",
    "            \n",
    "predictions = open(\"predictions_Purchase.csv\", 'w')\n",
    "\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    common = 0\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    new_c = set(item_category_dict[i])\n",
    "    user_c = set(user_category_dict[u])\n",
    "    if len(user_c) <> 0:\n",
    "        similarity = jaccard_similarity(new_c,user_c)\n",
    "        if similarity >= 0.182:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Combining similarity and most popular item concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for user, item in zip(users, items):\n",
    "    itemCount[item] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(itemCount[x], x) for x in itemCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "user_category_dict = defaultdict(list)\n",
    "item_category_dict = defaultdict(list)\n",
    "\n",
    "for u,i,c in zip(users, items, category):\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat not in user_category_dict[u]:\n",
    "                user_category_dict[u].append(subcat)\n",
    "            if subcat not in item_category_dict[i]: \n",
    "                item_category_dict[i].append(subcat)\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases*0.53: break\n",
    "           \n",
    "predictions = open(\"predictions_Purchase.csv\", 'w')\n",
    "\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    common = 0\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    new_c = set(item_category_dict[i])\n",
    "    user_c = set(user_category_dict[u])\n",
    "    if len(user_c) <> 0:\n",
    "        similarity = jaccard_similarity(new_c,user_c)\n",
    "        if similarity >= 0.182 or i in return1:\n",
    "            predictions.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + \",0\\n\")\n",
    "    elif len(user_c) == 0 and i in return1:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating Prediction\n",
    "\n",
    "## Model 1 - Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Rating prediction ##########3\n",
    "\n",
    "userRating_train = defaultdict(list)\n",
    "userRatings = defaultdict(list)\n",
    "itemRatings = defaultdict(list)\n",
    "itemCategory_train = defaultdict(list)\n",
    "userItem_train = defaultdict(list)\n",
    "\n",
    "for u,i,r,c in zip(users_train, items_train, ratings_train, category_train):\n",
    "    userRating_train[u].append((i,r))\n",
    "    userItem_train[u].append(i)\n",
    "    userRatings[u].append(r)\n",
    "    itemRatings[i].append(r)\n",
    "    for sublist in c:\n",
    "        for subcat in sublist:\n",
    "            if subcat not in itemCategory_train[i]:\n",
    "                itemCategory_train[i].append(subcat)\n",
    "                \n",
    "globalAvg = np.mean(ratings_train)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "      userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "        \n",
    "itemAverage = {}\n",
    "for i in itemRatings:\n",
    "      itemAverage[i] = sum(itemRatings[i]) / len(itemRatings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1,set2):\n",
    "    common = set1.intersection(set2)\n",
    "    return float(len(common)) / (len(set1) + len(set2) - len(common))\n",
    "\n",
    "pred_rating = []\n",
    "\n",
    "for u,i in zip(users_val, items_val):\n",
    "    category_i = set(itemCategory_train[i])\n",
    "    user_ratings = userRating_train[u]\n",
    "    if u in userItem_train.keys() and len(category_i) <> 0:\n",
    "        rating_temp = 0.0\n",
    "        sim = 0\n",
    "        for j,r in user_ratings:\n",
    "            category_j = set(itemCategory_train[j])\n",
    "            sim = jaccard_similarity(category_i,category_j)\n",
    "            rating_temp += round(r*sim,4)\n",
    "            sim_norm += sim\n",
    "        if sim_norm <> 0:\n",
    "            rating = round(rating_temp/sim_norm,4)\n",
    "            if rating > 5:\n",
    "                pred_rating.append(5)\n",
    "            elif rating < 0:\n",
    "                pred_rating.append(0)\n",
    "            else:\n",
    "                pred_rating.append(rating)\n",
    "        else:\n",
    "            pred_rating.append(round(rating_temp,4))\n",
    "    elif u not in userItem_train.keys() and len(category_i) <> 0:\n",
    "        pred_rating.append(itemAverage[i])\n",
    "    elif u in userItem_train.keys() and len(category_i) == 0:\n",
    "        pred_rating.append(userAverage[u])\n",
    "    else:\n",
    "        pred_rating.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(ratings_val) - np.array(pred_rating)\n",
    "MSE = sum(diff*diff.T)/len(pred_rating)\n",
    "print MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Latent Factor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(lam, usersTrain, itemsTrain, ratingTrain):\n",
    "    \n",
    "    userRating_train, itemRating_train = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    for u,i,r in zip(usersTrain, itemsTrain, ratingTrain):\n",
    "        userRating_train[u].append((i,r))\n",
    "        itemRating_train[i].append((u,r))  \n",
    "    \n",
    "    alpha, alpha_temp, iteration = 0, 0, 0\n",
    "    betaUser, betaItem =  defaultdict(float), defaultdict(float)\n",
    "    betaUser_temp, betaItem_temp = defaultdict(float),defaultdict(float)\n",
    "\n",
    "    for u in usersTrain:\n",
    "        betaUser[u], betaUser_temp[u] = 0, 0\n",
    "    for i in itemsTrain:\n",
    "        betaItem[i], betaItem_temp[i] = 0, 0\n",
    "\n",
    "    while iteration <= 500:\n",
    "        #betaUser\n",
    "        for u in betaUser.keys():\n",
    "            denominator = lam + len(userRating_train[u])\n",
    "            user_ratings = userRating_train[u]\n",
    "            numerator = 0\n",
    "            for i,r in user_ratings:\n",
    "                numerator += (r - (alpha + betaItem[i]))\n",
    "            betaUser_temp[u] = numerator*1.0/denominator\n",
    "        #betaItem\n",
    "        for i in betaItem.keys():\n",
    "            denominator = lam + len(itemRating_train[i])\n",
    "            item_ratings = itemRating_train[i]\n",
    "            numerator = 0\n",
    "            for u,r in item_ratings:\n",
    "                numerator += (r - (alpha + betaUser[u]))\n",
    "            betaItem_temp[i] = numerator*1.0/denominator\n",
    "        #alpha\n",
    "        numerator = 0\n",
    "        for u,i,r in zip(usersTrain, itemsTrain, ratingTrain):\n",
    "            numerator += (r - (betaUser[u] + betaItem[i]))\n",
    "        alpha_temp = numerator*1.0/len(usersTrain)\n",
    "\n",
    "        betaUser[u] = betaUser_temp[u]\n",
    "        betaItem[i] = betaItem_temp[i]\n",
    "        alpha = alpha_temp\n",
    "        \n",
    "        iteration += 1\n",
    "    \n",
    "    return(alpha, betaUser, betaItem)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = [0, 0.001,0.01,0.1,1,2,3,4]\n",
    "lamMSE = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-d22a2b896c33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetaUser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetaItem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mrating_pred_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-2c1310b3d3f4>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(lam, usersTrain, itemsTrain, ratingTrain)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mnumerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitem_ratings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mnumerator\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbetaUser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mbetaItem_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#alpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for l in lam:\n",
    "    alpha, betaUser, betaItem = gradient_descent(l, users_train, items_train, ratings_train)\n",
    "    \n",
    "    rating_pred_val = []\n",
    "    for u,i in zip(users_train, items_train):\n",
    "        prediction = alpha + betaUser[u] + betaItem[i]\n",
    "        if prediction > 5:\n",
    "            prediction = 5\n",
    "        elif prediction < 0:\n",
    "            prediction = 0\n",
    "        rating_pred_val.append(prediction)\n",
    "\n",
    "    diff = np.array(ratings_val) - np.array(rating_pred_val)\n",
    "    MSE = sum(diff*diff.T)/len(rating_pred_val)\n",
    "    \n",
    "    lamMSE[l] = MSE\n",
    "    \n",
    "lam = min(lamMSE, key = lamMSE.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print lamMSE\n",
    "print lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gradient_descent() takes exactly 6 arguments (4 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-b8767596aab0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetaUser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetaItem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallRatings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: gradient_descent() takes exactly 6 arguments (4 given)"
     ]
    }
   ],
   "source": [
    "lam = 3\n",
    "alpha, betaUser, betaItem = gradient_descent(lam, users, items, allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ratings = open(\"predictions_Rating.csv\", 'w')\n",
    "\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions_ratings.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    prediction = alpha + betaUser[u] + betaItem[i]\n",
    "    if prediction > 5:\n",
    "        prediction = 5\n",
    "    elif prediction < 0:\n",
    "        prediction = 0\n",
    "    \n",
    "    predictions_ratings.write(u + '-' + i + ',' + str(prediction) + '\\n')\n",
    "\n",
    "    \n",
    "predictions_ratings.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0002995004396604"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0010002/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
