{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import urllib\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "def parseData(filename):\n",
    "    for l in urllib.urlopen(filename):\n",
    "        yield eval(l)\n",
    "        \n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def feat(datum):\n",
    "    r = ''.join([c for c in d['review/text'].lower() if c not in punctuation])\n",
    "    return r\n",
    "\n",
    "processed_data = [feat(d) for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique bigrams in all revies: 195795\n"
     ]
    }
   ],
   "source": [
    "bigrams = [b for l in processed_data for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\n",
    "print(\"Number of unique bigrams in all revies: \")+str(len(set(bigrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent 5 bigrams:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4582, ('with', 'a')),\n",
       " (2576, ('in', 'the')),\n",
       " (2242, ('of', 'the')),\n",
       " (2053, ('is', 'a')),\n",
       " (2022, ('on', 'the')),\n",
       " (1878, ('a', 'bit'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramCount = defaultdict(int)\n",
    "for i in bigrams:\n",
    "    bigramCount[i] += 1\n",
    "\n",
    "freq = [(bigramCount[i],i) for i in bigramCount]\n",
    "freq.sort(reverse = True)\n",
    "\n",
    "print \"Most frequent 5 bigrams:\"\n",
    "freq[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_sets = [x[1] for x in freq[:1000]]\n",
    "bigramID = dict(zip(bigrams_sets, range(len(bigrams_sets))))\n",
    "uniqueBigrams = set(bigrams_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*len(uniqueBigrams)\n",
    "    r = [b for b in zip(datum.split(\" \")[:-1], datum.split(\" \")[1:])]\n",
    "    for bg in r:\n",
    "        if bg in bigrams_sets:\n",
    "            feat[bigramID[bg]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in processed_data]\n",
    "y = [d['review/overall'] for d in data]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.346067568549\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept = False)\n",
    "clf.fit(X,y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "diff = np.array(y) - np.array(predictions)\n",
    "MSE = float(sum(diff*diff.T))/len(predictions)\n",
    "print(\"MSE = \")+str(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF foam = 1.13786862069\n",
      "IDF smell = 0.537901618865\n",
      "IDF banana = 1.67778070527\n",
      "IDF lactic = 2.92081875395\n",
      "IDF tart = 1.80687540165\n",
      "TF-IDS score for foam: 2.27573724137\n",
      "TF-IDS score for smell: 0.537901618865\n",
      "TF-IDS score for banana: 3.35556141053\n",
      "TF-IDS score for lactic: 5.8416375079\n",
      "TF-IDS score for tart: 1.80687540165\n"
     ]
    }
   ],
   "source": [
    "d_foam, d_smell, d_banana, d_lactic, d_tart = 0, 0, 0, 0, 0\n",
    "for r in processed_data:\n",
    "    if 'foam' in r.split():\n",
    "        d_foam += 1\n",
    "    if 'smell' in r.split():\n",
    "        d_smell += 1\n",
    "    if 'banana' in r.split():\n",
    "        d_banana += 1\n",
    "    if 'lactic' in r.split():\n",
    "        d_lactic += 1\n",
    "    if 'tart' in r.split():\n",
    "        d_tart += 1\n",
    "\n",
    "tf = defaultdict(int)\n",
    "for w in processed_data[0].split():\n",
    "    tf[w] += 1\n",
    "    \n",
    "N = float(len(processed_data))\n",
    "\n",
    "print('IDF foam = ') + str(math.log10(N/d_foam))\n",
    "print('IDF smell = ') + str(math.log10(N/d_smell))\n",
    "print('IDF banana = ') + str(math.log10(N/d_banana))\n",
    "print('IDF lactic = ') + str(math.log10(N/d_lactic))\n",
    "print('IDF tart = ') + str(math.log10(N/d_tart))\n",
    "\n",
    "print('TF-IDS score for foam: ') + str(tf['foam']*math.log10(N/d_foam))\n",
    "print('TF-IDS score for smell: ') + str(tf['smell']*math.log10(N/d_smell))\n",
    "print('TF-IDS score for banana: ') + str(tf['banana']*math.log10(N/d_banana))\n",
    "print('TF-IDS score for lactic: ') + str(tf['lactic']*math.log10(N/d_lactic))\n",
    "print('TF-IDS score for tart: ') + str(tf['tart']*math.log10(N/d_tart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "for d in processed_data:\n",
    "    for w in d.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "words = [x[1] for x in counts]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "\n",
    "tf1 = Counter(processed_data[0].split())\n",
    "tf2 = Counter(processed_data[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(int)\n",
    "N = float(len(processed_data))\n",
    "\n",
    "for l in processed_data:\n",
    "    for w in wordSet:\n",
    "        if w in l.split():\n",
    "            df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between review 1 and 2 is 0.06588193974744383\n"
     ]
    }
   ],
   "source": [
    "tfidf1, tfidf2 = [], []\n",
    "\n",
    "for w in wordSet:\n",
    "    tfidf1.append(tf1[w]*np.log10(N/df[w]))\n",
    "    tfidf2.append(tf2[w]*np.log10(N/df[w]))\n",
    "\n",
    "from scipy import spatial\n",
    "cosine_similarity = 1 - spatial.distance.cosine(tfidf1, tfidf2)\n",
    "print(\"Cosine similarity between review 1 and 2 is \")+str(cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "best_cosine_similarity = cosine_similarity\n",
    "\n",
    "for l in processed_data[1:]:\n",
    "    tf = Counter(l.split())\n",
    "    tfidf = []\n",
    "    for w in wordSet:\n",
    "        tfidf.append(tf[w]*np.log10(N/df[w]))\n",
    "    cosine_similarity_new = 1 - spatial.distance.cosine(tfidf1, tfidf)\n",
    "    if cosine_similarity_new > best_cosine_similarity:\n",
    "        best_cosine_similarity = cosine_similarity_new\n",
    "        rev_num = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review one is most similar to 2343 having cosine similarity 0.2968679537499197\n",
      "Beer ID: 72146\n",
      "Profile Name: spicelab\n",
      "Review: 750mL bottle thanks to Chris@Slowbeer. Poured into a Lost Abbey stemmed tulip.\t\tGolden orange, close to translucent (on the first pour at least), capped by a sizable white, typically Belgian-looking head. Good lacing.\t\tQuite strong lactic notes and a sharp organic funk. Pungent stuff. Underneath is bitter citrus pith, floral spice and a hint of sweet esters. In your face with a lot going on. Only issue is the lactic character verges on turning my stomach.\t\tMore citric sourness and a bit less lactic character. Grapefruit and lemon rind are prominent, as is the Nelson Sauvin vegetative character, which kind of adheres to the yeast and barnyard funk. Tropical melons and honey provide some sweetness. Decent peppery tang.\t\tMedium, lightly syrupy body with lowish carbonation and a moderately tart, dry finish that has some length to it.\t\tIncomparable to anything I've tried. The Sauvin hops with the Saison yeast is a masterful combination, however there's no shortage of rough edges, which prevents an amazing or highly drinkable result.\n"
     ]
    }
   ],
   "source": [
    "print(\"Review one is most similar to \")+str(rev_num)+(\" having cosine similarity \")+ str(best_cosine_similarity)\n",
    "print(\"Beer ID: \") + data[rev_num]['beer/beerId']\n",
    "print(\"Profile Name: \") + data[rev_num]['user/profileName']\n",
    "print(\"Review: \") + data[rev_num]['review/text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.sort(reverse = True)\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def tfidf(datum):\n",
    "    feat = []\n",
    "    tf = Counter(datum.split())\n",
    "    for w in wordSet:\n",
    "        feat.append(tf[w]*np.log10(N/df[w]))\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "X = [tfidf(d) for d in processed_data]\n",
    "y = [d['review/overall'] for d in data]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.278759560078\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept = False)\n",
    "clf.fit(X,y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "diff = np.array(y) - np.array(predictions)\n",
    "MSE = float(sum(diff*diff.T))/len(predictions)\n",
    "print(\"MSE = \")+str(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
